{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import requests\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from fitter import Fitter, get_common_distributions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataframe(data):\n",
    "    if isinstance(data, dict) and all(\n",
    "        not isinstance(val, (list, dict)) for val in data.values()\n",
    "    ):\n",
    "        df = pd.DataFrame([data])  # Wrap the dict inside a list\n",
    "    else:\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_scheduled_elapsed_time(df: pd.DataFrame):\n",
    "    # Convert columns to string type\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(str)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(str)\n",
    "\n",
    "    # Pad columns with leading zeros to ensure it has 4 digits\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].str.zfill(4)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "    # Replace '2400' with '0000' in columns\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].replace(\"2400\", \"0000\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].replace(\"2400\", \"0000\")\n",
    "\n",
    "    # Convert columns to datetime format\n",
    "    df[\"ScheduledArrTime\"] = pd.to_datetime(df[\"ScheduledArrTime\"], format=\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = pd.to_datetime(df[\"ScheduledDepTime\"], format=\"%H%M\")\n",
    "\n",
    "    # Calculate the scheduled elapsed time and create a new column 'ScheduledElapsedTime'\n",
    "    df[\"ScheduledElapsedTime\"] = (\n",
    "        (\n",
    "            df[\"ScheduledArrTime\"] - df[\"ScheduledDepTime\"] + pd.Timedelta(days=1)\n",
    "        ).dt.total_seconds()\n",
    "        / 60\n",
    "    ).astype(int)\n",
    "\n",
    "    # Use modulo operation to limit the elapsed time within 24 hours\n",
    "    df[\"ScheduledElapsedTime\"] = df[\"ScheduledElapsedTime\"] % (24 * 60)\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' back to the original format\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].dt.strftime(\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].dt.strftime(\"%H%M\")\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' to int\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(int)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_col(df: pd.DataFrame):\n",
    "    # Convert the date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Create the Day, Month and Year columns\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_DayOfWeek(df: pd.DataFrame):\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\"address\": address, \"key\": \"AIzaSyCeWJLbBvTsN3WoA7R8y4M3DzGkKQHJp80\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "            location = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "            return location[\"lat\"], location[\"lng\"]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_conditions(lat, long, start_date, end_date):\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession(\".cache\", expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    date_object = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    if date_object < yesterday:\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    else:\n",
    "        url = \"https://api.open-meteo.com/v1/gfs\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"rain\",\n",
    "            \"snowfall\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_direction_10m\",\n",
    "        ],\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = responses[0].Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_rain = hourly.Variables(2).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_snowfall = hourly.Variables(3).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_direction_10m = hourly.Variables(5).ValuesAsNumpy()  # type:ignore\n",
    "\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),  # type: ignore\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),  # type: ignore\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),  # type: ignore\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    hourly_data[\"Temperature\"] = hourly_temperature_2m  # type:ignore\n",
    "    hourly_data[\"Precipitation\"] = hourly_precipitation  # type:ignore\n",
    "    hourly_data[\"Rain\"] = hourly_rain  # type:ignore\n",
    "    hourly_data[\"SnowFall\"] = hourly_snowfall  # type:ignore\n",
    "    hourly_data[\"WindSpeed\"] = hourly_wind_speed_10m  # type:ignore\n",
    "    hourly_data[\"WindDirection\"] = hourly_wind_direction_10m  # type:ignore\n",
    "\n",
    "    return pd.DataFrame(data=hourly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_airport_names(df: pd.DataFrame):\n",
    "    df[\"OrgAirport\"] = df[\"OrgAirport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"OrgAirport\"] = df[\"OrgAirport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df[\"DestAirport\"] = df[\"DestAirport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"DestAirport\"] = df[\"DestAirport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_weather_conditions_cols(df: pd.DataFrame):\n",
    "    weather_columns = [\n",
    "        \"Temperature\",\n",
    "        \"WindSpeed\",\n",
    "        \"WindDirection\",\n",
    "        \"Precipitation\",\n",
    "        \"Rain\",\n",
    "        \"SnowFall\",\n",
    "    ]\n",
    "    for prefix in [\"Dep\", \"Arr\"]:\n",
    "        for column in weather_columns:\n",
    "            df[f\"{prefix}{column}\"] = None\n",
    "    return weather_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_locations_dict(unique_locations, df: pd.DataFrame):\n",
    "    locations_dict = {value: pd.DataFrame() for value in unique_locations}\n",
    "    for i in range(len(unique_locations)):\n",
    "        lat, long = geocode(unique_locations[i])\n",
    "\n",
    "        if lat != None and long != None:\n",
    "            locations_dict[unique_locations[i]] = get_weather_conditions(\n",
    "                lat,\n",
    "                long,\n",
    "                str(df[\"Date\"].iloc[0]).split(\" \")[0],\n",
    "                str(df[\"Date\"].iloc[0]).split(\" \")[0],\n",
    "            )\n",
    "    return locations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_condtions(locations_dict, weather_columns, df):\n",
    "    j = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if (\n",
    "            not locations_dict[row[\"OrgAirport\"]].empty\n",
    "            and not locations_dict[row[\"DestAirport\"]].empty\n",
    "        ):\n",
    "            # Create temporary DataFrames for the operation\n",
    "            df_row = pd.DataFrame(row).transpose().copy()\n",
    "            dep_df = locations_dict[row[\"OrgAirport\"]].copy()\n",
    "            arr_df = locations_dict[row[\"DestAirport\"]].copy()\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].astype(str)\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].astype(str)\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledDepTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledDepTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "            df_row[\"ScheduledArrTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledArrTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledArrTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "\n",
    "            df_row[\"DepDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledDepTime\"]\n",
    "            df_row[\"ArrDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledArrTime\"]\n",
    "\n",
    "            # Convert 'Date' column in df2 to Datetime format without timezone\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.tz_convert(None)\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.tz_convert(None)\n",
    "\n",
    "            # # Extract Date and hour from 'DateTime' in df1 and 'Date' in df2\n",
    "            df_row[\"DepDateTime\"] = pd.to_datetime(df_row[\"DepDateTime\"]).dt.floor(\"h\")\n",
    "            df_row[\"ArrDateTime\"] = pd.to_datetime(df_row[\"ArrDateTime\"]).dt.floor(\"h\")\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.floor(\"h\")\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.floor(\"h\")\n",
    "\n",
    "            # # Merge the two DataFrames on the Datetime column\n",
    "            dep_weather = pd.merge(\n",
    "                df_row, dep_df, left_on=\"DepDateTime\", right_on=\"date\"\n",
    "            )\n",
    "            arr_weather = pd.merge(\n",
    "                df_row, arr_df, left_on=\"ArrDateTime\", right_on=\"date\"\n",
    "            )\n",
    "\n",
    "            # # Drop the temporary columns\n",
    "            dep_weather = dep_weather.drop(columns=[\"DepDateTime\", \"date\"])\n",
    "            arr_weather = arr_weather.drop(columns=[\"ArrDateTime\", \"date\"])\n",
    "\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = dep_weather[column][0]\n",
    "                df.at[index, f\"Arr{column}\"] = arr_weather[column][0]\n",
    "\n",
    "            j += 1\n",
    "        else:\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = 0\n",
    "                df.at[index, f\"Arr{column}\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_conditons_cols(df: pd.DataFrame):\n",
    "    correct_airport_names(df)\n",
    "\n",
    "    unique_locations = (\n",
    "        pd.concat([df[\"OrgAirport\"], df[\"DestAirport\"]]).unique().tolist()\n",
    "    )\n",
    "\n",
    "    # Create new columns in the DataFrame for weather conditions\n",
    "    weather_columns = insert_weather_conditions_cols(df)\n",
    "\n",
    "    # Create a dictionary with unique locations as keys and empty DataFrames as values\n",
    "    locations_dict = create_locations_dict(unique_locations, df)\n",
    "\n",
    "    # Match the weather conditions with the departure and arrival times\n",
    "    add_weather_condtions(locations_dict, weather_columns, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_Prediction(df):\n",
    "    with open(\"Utilities/column-names.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    Columns_List = text.split(\"\\n\")\n",
    "\n",
    "    Cols_List = [item.strip() for item in Columns_List if item.strip()]\n",
    "\n",
    "    train_df = pd.DataFrame(columns=Cols_List, index=range(0, len(df)))\n",
    "\n",
    "    train_df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"]\n",
    "    train_df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"]\n",
    "    train_df[\"ScheduledElapsedTime\"] = df[\"ScheduledElapsedTime\"]\n",
    "    train_df[\"Distance\"] = df[\"Distance\"]\n",
    "    train_df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    train_df[\"DepTemperature\"] = df[\"DepTemperature\"]\n",
    "    train_df[\"DepWindSpeed\"] = df[\"DepWindSpeed\"]\n",
    "    train_df[\"DepWindDirection\"] = df[\"DepWindDirection\"]\n",
    "    train_df[\"DepPrecipitation\"] = df[\"DepPrecipitation\"]\n",
    "    train_df[\"DepRain\"] = df[\"DepRain\"]\n",
    "    train_df[\"DepSnowFall\"] = df[\"DepSnowFall\"]\n",
    "    train_df[\"ArrTemperature\"] = df[\"ArrTemperature\"]\n",
    "    train_df[\"ArrWindSpeed\"] = df[\"ArrWindSpeed\"]\n",
    "    train_df[\"ArrWindDirection\"] = df[\"ArrWindDirection\"]\n",
    "    train_df[\"ArrPrecipitation\"] = df[\"ArrPrecipitation\"]\n",
    "    train_df[\"ArrRain\"] = df[\"ArrRain\"]\n",
    "    train_df[\"ArrSnowFall\"] = df[\"ArrSnowFall\"]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        DP_Airline = \"UniqueCarrier_\" + row[\"UniqueCarrier\"]\n",
    "        train_df.at[index, DP_Airline] = 1\n",
    "\n",
    "        DP_TailNum = \"TailNum_\" + row[\"TailNum\"]\n",
    "        train_df.at[index, DP_TailNum] = 1\n",
    "\n",
    "        DP_Origin = \"OrgAirportCode_\" + row[\"OrgAirportCode\"]\n",
    "        train_df.at[index, DP_Origin] = 1\n",
    "\n",
    "        DP_Dest = \"DestAirportCode_\" + row[\"DestAirportCode\"]\n",
    "        train_df.at[index, DP_Dest] = 1\n",
    "\n",
    "        DP_Weekday = \"DayOfWeek_\" + str(row[\"DayOfWeek\"])\n",
    "        train_df.at[index, DP_Weekday] = 1\n",
    "\n",
    "        DP_Month = \"Month_\" + str(row[\"Date\"].month)\n",
    "        train_df.at[index, DP_Month] = 1\n",
    "\n",
    "        train_df.fillna(0, inplace=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_Training(df):\n",
    "    # Extract day from date\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "\n",
    "    # One-hot encoding for categorical columns\n",
    "    categorical_cols = [\"UniqueCarrier\", \"TailNum\", \"OrgAirportCode\", \"DestAirportCode\"]\n",
    "    for col in categorical_cols:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    # One-hot encoding for DayOfWeek and Month\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"DayOfWeek\"], prefix=\"DayOfWeek\")], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"Date\"].dt.month, prefix=\"Month\")], axis=1)\n",
    "\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"UniqueCarrier\",\n",
    "            \"TailNum\",\n",
    "            \"OrgAirportCode\",\n",
    "            \"DestAirportCode\",\n",
    "            \"DayOfWeek\",\n",
    "            \"Date\",\n",
    "            \"AirlineName\",\n",
    "            \"OrgAirport\",\n",
    "            \"DestAirport\",\n",
    "            \"Month\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(df: pd.DataFrame):\n",
    "    stats = pd.read_csv(\"Utilities/stats.csv\")\n",
    "\n",
    "    for row in range(len(stats)):\n",
    "        column = stats[\"Column_Name\"].iloc[row]\n",
    "        if stats[\"Distribution\"].iloc[row] == \"norm\":\n",
    "            mean = stats[\"Mean\"].iloc[row]\n",
    "            sd = stats[\"Standard_Deviation\"].iloc[row]\n",
    "            df[column] = (df[column] - mean) / sd\n",
    "\n",
    "        elif stats[\"Distribution\"].iloc[row] == \"uniform\":\n",
    "            if df[column].iloc[0] < stats[\"Min\"].iloc[row]:\n",
    "                stats.at[row, \"Min\"] = df[column]\n",
    "            elif df[column].iloc[0] > stats[\"Max\"].iloc[row]:\n",
    "                stats.at[row, \"Max\"] = df[column]\n",
    "\n",
    "            min = stats[\"Min\"].iloc[row]\n",
    "            max = stats[\"Max\"].iloc[row]\n",
    "            df[column] = (df[column] - min) / (max - min)\n",
    "\n",
    "        else:\n",
    "            data = np.array(df[column]).reshape(-1, 1)\n",
    "            df[column] = np.log(np.abs(np.float32(data.flatten())) + 0.1)\n",
    "\n",
    "    stats.to_csv(\"Utilities/stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_data(data, dist):\n",
    "    if dist == \"uniform\":\n",
    "        return MinMaxScaler().fit_transform(data)\n",
    "    elif dist == \"norm\":\n",
    "        return StandardScaler().fit_transform(data)\n",
    "    else:\n",
    "        return np.log(np.abs(np.float32(data.flatten())) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_distribution(df: pd.DataFrame):\n",
    "    numeric_columns = [\n",
    "        \"ScheduledArrTime\",\n",
    "        \"ScheduledDepTime\",\n",
    "        \"ScheduledElapsedTime\",\n",
    "        \"Distance\",\n",
    "        \"DepTemperature\",\n",
    "        \"DepWindSpeed\",\n",
    "        \"DepWindDirection\",\n",
    "        \"DepPrecipitation\",\n",
    "        \"DepRain\",\n",
    "        \"DepSnowFall\",\n",
    "        \"ArrTemperature\",\n",
    "        \"ArrWindSpeed\",\n",
    "        \"ArrWindDirection\",\n",
    "        \"ArrPrecipitation\",\n",
    "        \"ArrRain\",\n",
    "        \"ArrSnowFall\",\n",
    "        \"Day\",\n",
    "    ]\n",
    "\n",
    "    columns_distributions_dict = {column: \"\" for column in numeric_columns}\n",
    "\n",
    "    for column in numeric_columns:\n",
    "        print(\"###### \" + column + \" ######\")\n",
    "\n",
    "        data = df[column].values\n",
    "\n",
    "        f = Fitter(\n",
    "            data,\n",
    "            distributions=get_common_distributions(),\n",
    "        )\n",
    "        f.fit()\n",
    "        f.summary(plot=False)\n",
    "        dist = f.get_best(method=\"sumsquare_error\")\n",
    "        best_dist = \"\"\n",
    "        for key in dist.keys():\n",
    "            best_dist = key\n",
    "\n",
    "        columns_distributions_dict[column] = str(best_dist)\n",
    "        print(column)\n",
    "        print(f\"Best Distribution: {best_dist}\")\n",
    "        print()\n",
    "\n",
    "    return columns_distributions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df: pd.DataFrame):\n",
    "    columns_distributions_dict = get_best_distribution(df)\n",
    "\n",
    "    for column in columns_distributions_dict.keys():\n",
    "        data = np.array(df[column]).reshape(-1, 1)\n",
    "        df[column] = get_normalized_data(\n",
    "            data=data, dist=columns_distributions_dict[column]\n",
    "        )\n",
    "\n",
    "    return columns_distributions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(df: pd.DataFrame, dist_dict: dict):\n",
    "    stats = []\n",
    "    for c in dist_dict:\n",
    "\n",
    "        mean_value = df[c].mean()\n",
    "        min_value = df[c].min()\n",
    "        max_value = df[c].max()\n",
    "        sd = df[c].std()\n",
    "        dist = dist_dict[c]\n",
    "\n",
    "        stats.append(\n",
    "            {\n",
    "                \"Column_Name\": c,\n",
    "                \"Min\": min_value,\n",
    "                \"Max\": max_value,\n",
    "                \"Mean\": mean_value,\n",
    "                \"Standard_Deviation\": sd,\n",
    "                \"Distribution\": dist,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    stats_df.to_csv(\"Utilities/stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessForPrediction(data):\n",
    "    df = convertToDataframe(data)\n",
    "    insert_scheduled_elapsed_time(df)\n",
    "    expand_date_col(df)\n",
    "    insert_DayOfWeek(df)\n",
    "    create_weather_conditons_cols(df)\n",
    "    train_df = OHE_Prediction(df)\n",
    "    train_df.drop(columns=[\"IsDelayed\"], inplace=True)\n",
    "    train_df_copy = train_df.copy()\n",
    "    normalize_row(train_df)\n",
    "    return train_df, train_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessForTraining(data):\n",
    "    df = convertToDataframe(data)\n",
    "    insert_scheduled_elapsed_time(df)\n",
    "    expand_date_col(df)\n",
    "    insert_DayOfWeek(df)\n",
    "    train_df = df.copy()\n",
    "    train_df = OHE_Training(train_df)\n",
    "    dist_dict = normalize_df(train_df)\n",
    "    compute_stats(df, dist_dict)\n",
    "    column = train_df.pop(\"IsDelayed\")\n",
    "    train_df.insert(len(train_df.columns), \"IsDelayed\", column)\n",
    "    X = train_df.iloc[:, :-1]\n",
    "    y = train_df.iloc[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(df: pd.DataFrame):\n",
    "    with open(\"model.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    prediction = model.predict(df)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(X: pd.DataFrame, y: pd.Series):\n",
    "    with open(\"model.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    model.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "    print(\"Finished training\")\n",
    "    with open(\"model.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def Predict():\n",
    "    data = request.json\n",
    "    train_df, train_df_copy = preprocessForPrediction(data)\n",
    "    prediction = getPrediction(train_df.to_numpy())\n",
    "    train_df_copy[\"IsDelayedPredicted\"] = prediction\n",
    "    return train_df_copy.to_dict(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/train\", methods=[\"POST\"])\n",
    "def Tain():\n",
    "    data = request.json\n",
    "    X, y = preprocessForTraining(data)\n",
    "    if TrainModel(X, y):\n",
    "        return \"1\"\n",
    "\n",
    "    return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(port=4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
