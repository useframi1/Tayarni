{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataframe(data):\n",
    "    if isinstance(data, dict) and all(\n",
    "        not isinstance(val, (list, dict)) for val in data.values()\n",
    "    ):\n",
    "        df = pd.DataFrame([data])  # Wrap the dict inside a list\n",
    "    else:\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_scheduled_elapsed_time(df: pd.DataFrame):\n",
    "    # Convert columns to string type\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(str)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(str)\n",
    "\n",
    "    # Pad columns with leading zeros to ensure it has 4 digits\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].str.zfill(4)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "    # Replace '2400' with '0000' in columns\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].replace(\"2400\", \"0000\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].replace(\"2400\", \"0000\")\n",
    "\n",
    "    # Convert columns to datetime format\n",
    "    df[\"ScheduledArrTime\"] = pd.to_datetime(df[\"ScheduledArrTime\"], format=\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = pd.to_datetime(df[\"ScheduledDepTime\"], format=\"%H%M\")\n",
    "\n",
    "    # Calculate the scheduled elapsed time and create a new column 'ScheduledElapsedTime'\n",
    "    df[\"ScheduledElapsedTime\"] = (\n",
    "        (\n",
    "            df[\"ScheduledArrTime\"] - df[\"ScheduledDepTime\"] + pd.Timedelta(days=1)\n",
    "        ).dt.total_seconds()\n",
    "        / 60\n",
    "    ).astype(int)\n",
    "\n",
    "    # Use modulo operation to limit the elapsed time within 24 hours\n",
    "    df[\"ScheduledElapsedTime\"] = df[\"ScheduledElapsedTime\"] % (24 * 60)\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' back to the original format\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].dt.strftime(\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].dt.strftime(\"%H%M\")\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' to int\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(int)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_col(df: pd.DataFrame):\n",
    "    # Convert the date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Create the Day, Month and Year columns\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_DayOfWeek(df: pd.DataFrame):\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\"address\": address, \"key\": \"AIzaSyCeWJLbBvTsN3WoA7R8y4M3DzGkKQHJp80\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "            location = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "            return location[\"lat\"], location[\"lng\"]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_conditions(lat, long, start_date, end_date):\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession(\".cache\", expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://api.open-meteo.com/v1/gfs\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"rain\",\n",
    "            \"snowfall\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_direction_10m\",\n",
    "        ],\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = responses[0].Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_rain = hourly.Variables(2).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_snowfall = hourly.Variables(3).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_direction_10m = hourly.Variables(5).ValuesAsNumpy()  # type:ignore\n",
    "\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),  # type: ignore\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),  # type: ignore\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),  # type: ignore\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    hourly_data[\"Temperature\"] = hourly_temperature_2m  # type:ignore\n",
    "    hourly_data[\"Precipitation\"] = hourly_precipitation  # type:ignore\n",
    "    hourly_data[\"Rain\"] = hourly_rain  # type:ignore\n",
    "    hourly_data[\"SnowFall\"] = hourly_snowfall  # type:ignore\n",
    "    hourly_data[\"WindSpeed\"] = hourly_wind_speed_10m  # type:ignore\n",
    "    hourly_data[\"WindDirection\"] = hourly_wind_direction_10m  # type:ignore\n",
    "\n",
    "    return pd.DataFrame(data=hourly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_airport_names(df: pd.DataFrame):\n",
    "    df[\"OrgAirport\"] = df[\"OrgAirport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"OrgAirport\"] = df[\"OrgAirport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df[\"DestAirport\"] = df[\"DestAirport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"DestAirport\"] = df[\"DestAirport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_weather_conditions_cols(df: pd.DataFrame):\n",
    "    weather_columns = [\n",
    "        \"Temperature\",\n",
    "        \"WindSpeed\",\n",
    "        \"WindDirection\",\n",
    "        \"Precipitation\",\n",
    "        \"Rain\",\n",
    "        \"SnowFall\",\n",
    "    ]\n",
    "    for prefix in [\"Dep\", \"Arr\"]:\n",
    "        for column in weather_columns:\n",
    "            df[f\"{prefix}{column}\"] = None\n",
    "    return weather_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_locations_dict(unique_locations, df: pd.DataFrame):\n",
    "    locations_dict = {value: pd.DataFrame() for value in unique_locations}\n",
    "    for i in range(len(unique_locations)):\n",
    "        lat, long = geocode(unique_locations[i])\n",
    "\n",
    "        if lat != None and long != None:\n",
    "            locations_dict[unique_locations[i]] = get_weather_conditions(\n",
    "                lat,\n",
    "                long,\n",
    "                str(df[\"Date\"].iloc[0]).split(\" \")[0],\n",
    "                str(df[\"Date\"].iloc[0]).split(\" \")[0],\n",
    "            )\n",
    "    return locations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_condtions(locations_dict, weather_columns, df):\n",
    "    j = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if (\n",
    "            not locations_dict[row[\"OrgAirport\"]].empty\n",
    "            and not locations_dict[row[\"DestAirport\"]].empty\n",
    "        ):\n",
    "            # Create temporary DataFrames for the operation\n",
    "            df_row = pd.DataFrame(row).transpose().copy()\n",
    "            dep_df = locations_dict[row[\"OrgAirport\"]].copy()\n",
    "            arr_df = locations_dict[row[\"DestAirport\"]].copy()\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].astype(str)\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].astype(str)\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledDepTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledDepTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "            df_row[\"ScheduledArrTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledArrTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledArrTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "\n",
    "            df_row[\"DepDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledDepTime\"]\n",
    "            df_row[\"ArrDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledArrTime\"]\n",
    "\n",
    "            # Convert 'Date' column in df2 to Datetime format without timezone\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.tz_convert(None)\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.tz_convert(None)\n",
    "\n",
    "            # # Extract Date and hour from 'DateTime' in df1 and 'Date' in df2\n",
    "            df_row[\"DepDateTime\"] = pd.to_datetime(df_row[\"DepDateTime\"]).dt.floor(\"h\")\n",
    "            df_row[\"ArrDateTime\"] = pd.to_datetime(df_row[\"ArrDateTime\"]).dt.floor(\"h\")\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.floor(\"h\")\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.floor(\"h\")\n",
    "\n",
    "            # # Merge the two DataFrames on the Datetime column\n",
    "            dep_weather = pd.merge(\n",
    "                df_row, dep_df, left_on=\"DepDateTime\", right_on=\"date\"\n",
    "            )\n",
    "            arr_weather = pd.merge(\n",
    "                df_row, arr_df, left_on=\"ArrDateTime\", right_on=\"date\"\n",
    "            )\n",
    "\n",
    "            # # Drop the temporary columns\n",
    "            dep_weather = dep_weather.drop(columns=[\"DepDateTime\", \"date\"])\n",
    "            arr_weather = arr_weather.drop(columns=[\"ArrDateTime\", \"date\"])\n",
    "\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = dep_weather[column][0]\n",
    "                df.at[index, f\"Arr{column}\"] = arr_weather[column][0]\n",
    "\n",
    "            j += 1\n",
    "        else:\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = 0\n",
    "                df.at[index, f\"Arr{column}\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_conditons_cols(df: pd.DataFrame):\n",
    "    correct_airport_names(df)\n",
    "\n",
    "    unique_locations = (\n",
    "        pd.concat([df[\"OrgAirport\"], df[\"DestAirport\"]]).unique().tolist()\n",
    "    )\n",
    "\n",
    "    # Create new columns in the DataFrame for weather conditions\n",
    "    weather_columns = insert_weather_conditions_cols(df)\n",
    "\n",
    "    # Create a dictionary with unique locations as keys and empty DataFrames as values\n",
    "    locations_dict = create_locations_dict(unique_locations, df)\n",
    "\n",
    "    # Match the weather conditions with the departure and arrival times\n",
    "    add_weather_condtions(locations_dict, weather_columns, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_Prediction(df):\n",
    "    with open(\"Utilities/column-names.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    Columns_List = text.split(\"\\n\")\n",
    "\n",
    "    Cols_List = [item.strip() for item in Columns_List if item.strip()]\n",
    "\n",
    "    train_df = pd.DataFrame(columns=Cols_List, index=range(0, len(df)))\n",
    "\n",
    "    train_df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"]\n",
    "    train_df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"]\n",
    "    train_df[\"ScheduledElapsedTime\"] = df[\"ScheduledElapsedTime\"]\n",
    "    train_df[\"Distance\"] = df[\"Distance\"]\n",
    "    train_df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    train_df[\"DepTemperature\"] = df[\"DepTemperature\"]\n",
    "    train_df[\"DepWindSpeed\"] = df[\"DepWindSpeed\"]\n",
    "    train_df[\"DepWindDirection\"] = df[\"DepWindDirection\"]\n",
    "    train_df[\"DepPrecipitation\"] = df[\"DepPrecipitation\"]\n",
    "    train_df[\"DepRain\"] = df[\"DepRain\"]\n",
    "    train_df[\"DepSnowFall\"] = df[\"DepSnowFall\"]\n",
    "    train_df[\"ArrTemperature\"] = df[\"ArrTemperature\"]\n",
    "    train_df[\"ArrWindSpeed\"] = df[\"ArrWindSpeed\"]\n",
    "    train_df[\"ArrWindDirection\"] = df[\"ArrWindDirection\"]\n",
    "    train_df[\"ArrPrecipitation\"] = df[\"ArrPrecipitation\"]\n",
    "    train_df[\"ArrRain\"] = df[\"ArrRain\"]\n",
    "    train_df[\"ArrSnowFall\"] = df[\"ArrSnowFall\"]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        DP_Airline = \"UniqueCarrier_\" + row[\"UniqueCarrier\"]\n",
    "        train_df.at[index, DP_Airline] = 1\n",
    "\n",
    "        DP_TailNum = \"TailNum_\" + row[\"TailNum\"]\n",
    "        train_df.at[index, DP_TailNum] = 1\n",
    "\n",
    "        DP_Origin = \"OrgAirportCode_\" + row[\"OrgAirportCode\"]\n",
    "        train_df.at[index, DP_Origin] = 1\n",
    "\n",
    "        DP_Dest = \"DestAirportCode_\" + row[\"DestAirportCode\"]\n",
    "        train_df.at[index, DP_Dest] = 1\n",
    "\n",
    "        DP_Weekday = \"DayOfWeek_\" + str(row[\"DayOfWeek\"])\n",
    "        train_df.at[index, DP_Weekday] = 1\n",
    "\n",
    "        DP_Month = \"Month_\" + str(row[\"Date\"].month)\n",
    "        train_df.at[index, DP_Month] = 1\n",
    "\n",
    "        train_df.fillna(0, inplace=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_Training(df):\n",
    "    # Extract day from date\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "\n",
    "    # One-hot encoding for categorical columns\n",
    "    categorical_cols = [\"UniqueCarrier\", \"TailNum\", \"OrgAirportCode\", \"DestAirportCode\"]\n",
    "    for col in categorical_cols:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    # One-hot encoding for DayOfWeek and Month\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"DayOfWeek\"], prefix=\"DayOfWeek\")], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"Date\"].dt.month, prefix=\"Month\")], axis=1)\n",
    "\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"UniqueCarrier\",\n",
    "            \"TailNum\",\n",
    "            \"OrgAirportCode\",\n",
    "            \"DestAirportCode\",\n",
    "            \"DayOfWeek\",\n",
    "            \"Date\",\n",
    "            \"AirlineName\",\n",
    "            \"OrgAirport\",\n",
    "            \"DestAirport\",\n",
    "            \"Month\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df: pd.DataFrame):\n",
    "    stats = pd.read_csv(\"Utilities/stats.csv\")\n",
    "    Nomralize_Dict = {\n",
    "        \"ScheduledArrTime\": \"Z\",\n",
    "        \"ScheduledDepTime\": \"Z\",\n",
    "        \"ScheduledElapsedTime\": \"Z\",\n",
    "        \"Distance\": \"Log\",\n",
    "        \"DepTemperature\": \"Z\",\n",
    "        \"DepWindSpeed\": \"Log\",\n",
    "        \"DepWindDirection\": \"Min\",\n",
    "        \"DepPrecipitation\": \"Z\",\n",
    "        \"DepRain\": \"Z\",\n",
    "        \"DepSnowFall\": \"Log\",\n",
    "        \"ArrTemperature\": \"Z\",\n",
    "        \"ArrWindSpeed\": \"Log\",\n",
    "        \"ArrWindDirection\": \"Min\",\n",
    "        \"ArrPrecipitation\": \"Z\",\n",
    "        \"ArrRain\": \"Z\",\n",
    "        \"ArrSnowFall\": \"Log\",\n",
    "        \"Day\": \"Min\",\n",
    "    }\n",
    "    for key, value in Nomralize_Dict.items():\n",
    "        if value == \"Z\":\n",
    "            row = stats[stats[\"Column_Name\"] == key]\n",
    "            mean = row[\"Mean\"].iloc[0]\n",
    "            sd = row[\"Standard_Deviation\"].iloc[0]\n",
    "            df[key] = (df[key] - mean) / sd\n",
    "\n",
    "        elif value == \"Log\":\n",
    "            data = np.array(df[key]).reshape(-1, 1)\n",
    "            df[key] = np.log(np.abs(np.float32(data.flatten())) + 0.1)\n",
    "\n",
    "        else:\n",
    "            row = stats[stats[\"Column_Name\"] == key]\n",
    "            min = row[\"Min\"].iloc[0]\n",
    "            max = row[\"Max\"].iloc[0]\n",
    "            df[key] = (df[key] - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessForPrediction(data):\n",
    "    df = convertToDataframe(data)\n",
    "    insert_scheduled_elapsed_time(df)\n",
    "    expand_date_col(df)\n",
    "    insert_DayOfWeek(df)\n",
    "    create_weather_conditons_cols(df)\n",
    "    train_df = OHE_Prediction(df)\n",
    "    train_df.drop(columns=[\"IsDelayed\"], inplace=True)\n",
    "    train_df_copy = train_df.copy()\n",
    "    normalize(train_df)\n",
    "    return train_df, train_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessForTraining(data):\n",
    "    df = convertToDataframe(data)\n",
    "    insert_scheduled_elapsed_time(df)\n",
    "    expand_date_col(df)\n",
    "    insert_DayOfWeek(df)\n",
    "    train_df = df.copy()\n",
    "    train_df = OHE_Training(train_df)\n",
    "    normalize(train_df)\n",
    "    column = train_df.pop(\"IsDelayed\")\n",
    "    train_df.insert(len(train_df.columns), \"IsDelayed\", column)\n",
    "    X = train_df.iloc[:, :-1]\n",
    "    y = train_df.iloc[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(df: pd.DataFrame):\n",
    "    with open(\"model.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    prediction = model.predict(df)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(X: pd.DataFrame, y: pd.Series):\n",
    "    with open(\"model.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    model.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "    print(\"Finished training\")\n",
    "    with open(\"model.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def Predict():\n",
    "    data = request.json\n",
    "    train_df, train_df_copy = preprocessForPrediction(data)\n",
    "    prediction = getPrediction(train_df.to_numpy())\n",
    "    train_df_copy[\"IsDelayedPredicted\"] = prediction\n",
    "    return train_df_copy.to_dict(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/train\", methods=[\"POST\"])\n",
    "def Tain():\n",
    "    data = request.json\n",
    "    X, y = preprocessForTraining(data)\n",
    "    if TrainModel(X, y):\n",
    "        return \"1\"\n",
    "\n",
    "    return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:4000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "[2024-05-06 11:55:37,423] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py\", line 963, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 491, in _make_request\n",
      "    raise new_e\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 1099, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py\", line 616, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py\", line 205, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x14c92c0b0>: Failed to resolve 'maps.googleapis.com' ([Errno 8] nodename nor servname provided, or not known)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/geocode/json?address=Abilene+Regional+Airport&key=AIzaSyCeWJLbBvTsN3WoA7R8y4M3DzGkKQHJp80 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x14c92c0b0>: Failed to resolve 'maps.googleapis.com' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/yf/v551qfjj6kv_0hzcql5wjr7w0000gn/T/ipykernel_82268/813927106.py\", line 4, in Predict\n",
      "    train_df, train_df_copy = preprocessForPrediction(data)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/yf/v551qfjj6kv_0hzcql5wjr7w0000gn/T/ipykernel_82268/3841325848.py\", line 6, in preprocessForPrediction\n",
      "    create_weather_conditons_cols(df)\n",
      "  File \"/var/folders/yf/v551qfjj6kv_0hzcql5wjr7w0000gn/T/ipykernel_82268/221842556.py\", line 12, in create_weather_conditons_cols\n",
      "    locations_dict = create_locations_dict(unique_locations, df)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/yf/v551qfjj6kv_0hzcql5wjr7w0000gn/T/ipykernel_82268/3939014551.py\", line 4, in create_locations_dict\n",
      "    lat, long = geocode(unique_locations[i])\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/yf/v551qfjj6kv_0hzcql5wjr7w0000gn/T/ipykernel_82268/3737629954.py\", line 4, in geocode\n",
      "    response = requests.get(url, params=params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/geocode/json?address=Abilene+Regional+Airport&key=AIzaSyCeWJLbBvTsN3WoA7R8y4M3DzGkKQHJp80 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x14c92c0b0>: Failed to resolve 'maps.googleapis.com' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "127.0.0.1 - - [06/May/2024 11:55:37] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "127.0.0.1 - - [06/May/2024 11:56:43] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(port=4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
